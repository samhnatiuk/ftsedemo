{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core modules\n",
    "import os\n",
    "from io import StringIO\n",
    "import json\n",
    "from typing import Callable, List, Dict, Any, Tuple\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import inspect\n",
    "from datetime import datetime\n",
    "\n",
    "# Data retrieval\n",
    "import yfinance as yf\n",
    "\n",
    "# Plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import hyperopt.plotting as hplt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Sklearn ML\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# Keras DL\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Hyperparameter optimisation\n",
    "from hyperopt import STATUS_OK, fmin, tpe, Trials, hp\n",
    "from functools import partial\n",
    "\n",
    "# Cloud services\n",
    "from azureml.core import Workspace\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Tracking\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "# data drift\n",
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# downloading data\n",
    "data = yf.download(\"^FTSE\", start=\"1999-12-01\", end=\"2021-12-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Close', axis=1, inplace=True)\n",
    "print(data.isnull().sum())\n",
    "print(data.eq(0).sum())\n",
    "print(data.index.diff().value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(data, x=data.index, y='Adj Close')\n",
    "fig.update_layout(title={'text': 'Closing price over time', 'x': 0.5})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasLogger:\n",
    "\n",
    "    def __init__(self, run_name: str):\n",
    "        current_dt = datetime.now().strftime(\"%y-%m-%d %h:%m:%s\")\n",
    "        self.run_name = f\"{run_name}_{current_dt}\"\n",
    "\n",
    "    def __call__(self, func: Callable):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            with mlflow.start_run(run_name=self.run_name):\n",
    "                mlflow.keras.autolog()\n",
    "                model, y_test, y_pred, losses = func(*args, **kwargs)\n",
    "\n",
    "                metrics = self.get_metrics(y_pred, y_test)\n",
    "                mlflow.log_metrics(metrics)\n",
    "\n",
    "                mlflow.keras.log_model(model, artifact_path=\"models\")\n",
    "\n",
    "                lossplt = self.plot_true_value_vs_prediction(y_pred, y_test)\n",
    "                mlflow.log_figure(lossplt, \"true_value_vs_prediction.png\")\n",
    "\n",
    "                epochplt = self.plot_loss_over_epoch(losses)\n",
    "                mlflow.log_figure(epochplt, \"loss_over_epochs.png\")\n",
    "\n",
    "                return model, y_test, y_pred, losses\n",
    "        \n",
    "        return wrapper\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def plot_true_value_vs_prediction(pred: np.ndarray, test: np.ndarray) -> plt.figure:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(test, label='True Value')\n",
    "        ax.plot(pred, label='LSTM Value')\n",
    "        ax.set_title('Prediction by LSTM')\n",
    "        ax.set_xlabel('Time Scale')\n",
    "        ax.set_ylabel('Scaled USD')\n",
    "        ax.legend()\n",
    "        return fig\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_loss_over_epoch(losses: List[float]) -> plt.figure:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(losses)\n",
    "        ax.set_title('Model Loss Over Epochs')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Loss')\n",
    "        return fig\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_metrics(pred: np.ndarray, test: np.ndarray) -> Dict[str, float]:\n",
    "        mse = mean_squared_error(test, pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(test, pred)\n",
    "        r2 = r2_score(test, pred)\n",
    "        msle = mean_squared_log_error(test, pred)\n",
    "        medae = median_absolute_error(test, pred)\n",
    "        return {\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"msle\": msle, \"medae\": medae}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runname = \"aalstm\"\n",
    "\n",
    "## Building LSTM mode\n",
    "@KerasLogger(run_name=runname)\n",
    "def train_lstm_model(df: pd.DataFrame,\n",
    "                test_size: int = 10,\n",
    "                loss: str = 'mean_squared_error',\n",
    "                activation: str = 'relu',\n",
    "                optimiser: str = 'adam',\n",
    "                n_epoch: int = 100,\n",
    "                batch_size: int = 8,\n",
    "                verbose: int = 1) -> Tuple[Sequential, np.ndarray, np.ndarray, List[float]]:\n",
    "\n",
    "    # defome featires, target\n",
    "    X, y = df.drop('Adj Close', , axis=1), data[['Adj Close']]\n",
    "\n",
    "    # svale features\n",
    "    X_scaled = MinMaxScaler().fit_transform(X)\n",
    "    X = pd.DataFrame(data=X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "    #Building the LSTM Model\n",
    "    lstm = Sequential()\n",
    "    lstm.add(LSTM(32, input_shape=(1, X.shape[1]), activation=activation, return_sequences=False))\n",
    "    lstm.add(Dense(1))\n",
    "    lstm.compile(loss=loss, optimizer=optimiser)\n",
    "\n",
    "    n_split = 100 // test_size - 1\n",
    "    timesplit = TimeSeriesSplit(n_splits=n_split)\n",
    "\n",
    "    losses = []\n",
    "    for i, (train_idx, test_idx) in enumerate(timesplit.split(X)):\n",
    "        print(f\"\\n\\n---Training model batch {i+1} out of {n_split}---\")\n",
    "        X_train = X[:len(train_idx)]\n",
    "        X_test = X[len(train_idx): (len(train_idx)+len(test_idx))]\n",
    "        y_train = y[:len(train_idx)].values.ravel()\n",
    "        y_test = y[len(train_idx): (len(train_idx)+len(test_idx))].values.ravel()\n",
    "\n",
    "        # reshapiong\n",
    "        X_train = np.array(X_train).reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "        hist = lstm.fit(X_train, y_train, epochs=n_epoch, batch_size=batch_size, verbose=verbose)\n",
    "        losses.extend(hist.history['loss'])\n",
    "    \n",
    "    X_test = np.array(X_test).reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "    y_pred = lstm.predict(X_test)\n",
    "    return lstm, y_test, y_pred, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
    "mlflow_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"demo4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lstm_model(data, n_epoch=5, test_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sklearn_regressor(hyperparams: Dict[str, Any],\n",
    "                X_train: pd.DataFrame,\n",
    "                X_test: pd.DataFrame,\n",
    "                y_train: pd.Series,\n",
    "                y_test: pd.Series,\n",
    "                model: BaseEstimator,\n",
    "                dtypes: Dict[str, Callable]) -> Dict[str, Any]:\n",
    "    \n",
    "    # map datatypes\n",
    "    for k, v in hyperparams.items():\n",
    "        if k in dtypes.keys():\n",
    "            hyperparams[k] = dtypes[k](v)\n",
    "    \n",
    "    model = model(**hyperparams)\n",
    "    hypervals = '_'.join([f'{key}: {value}' for key, value in hyperparams.items()])\n",
    "    run_name = f\"{type(model).__name__}_{hypervals}\"\n",
    "    with mlflow.start_run(nested=True, run_name=run_name) as child_run:\n",
    "        \n",
    "        mlflow.sklearn.autolog()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        msle = mean_squared_log_error(y_test, y_pred)\n",
    "        medae = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "        mlflow.log_metrics({\"mse\": mse, \"rmse\": rmse, \"mae\": mae, \"r2\": r2, \"msle\": msle, \"medae\": medae})\n",
    "    \n",
    "        return {'status': STATUS_OK, 'loss': mse, \"attachments\": {\"run_id\": child_run.info.run_id}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ChildRunData:\n",
    "    params: Dict[str, Any]\n",
    "    metrics: Dict[str, float]\n",
    "    model: BaseEstimator\n",
    "    run_id: str\n",
    "    run_name: str\n",
    "    experiment_id: str\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, run_id):\n",
    "        client = mlflow.tracking.MlflowClient()\n",
    "        run = mlflow.get_run(run_id)\n",
    "        metrics = run.data.metrics\n",
    "        params = run.data.params\n",
    "        models = client.download_artifacts(run_id, path=\"model\")\n",
    "        run_name = run.info.run_name\n",
    "        experiment_id = run.info.experiment_id\n",
    "\n",
    "        return cls(params, metrics, models, run_id, run_name, experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search(hyperparam_space: Dict[str, Any],\n",
    "           df: pd.DataFrame,\n",
    "           target: str,\n",
    "           model: BaseEstimator,\n",
    "           dtypes: Dict[str, Callable],\n",
    "           max_evals: int = 100) -> Tuple[Trials, Dict[str, Any]]:\n",
    "\n",
    "    X, y = df.drop(target, axis=1), df[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    with mlflow.start_run(nested=False, run_name=model.__name__):\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=partial(\n",
    "                train_sklearn_regressor, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, model=model, dtypes=dtypes\n",
    "                ),\n",
    "            space=hyperparam_space,\n",
    "            algo=tpe.suggest,\n",
    "            trials=trials,\n",
    "            max_evals=max_evals\n",
    "        )\n",
    "\n",
    "        best_run_id = trials.trial_attachments(trials.best_trial)[\"run_id\"]\n",
    "        best_run_data = ChildRunData.get(best_run_id)\n",
    "\n",
    "        mlflow.log_param(\"best_run_id\", best_run_id)\n",
    "        mlflow.log_params({f\"best_{p}\": v for p, v in best_params.items()})\n",
    "        mlflow.log_metric(\"best_mse\", trials.best_trial[\"result\"][\"loss\"])\n",
    "        mlflow.log_metrics(best_run_data.metrics)\n",
    "        mlflow.log_artifacts(local_dir=best_run_data.model, artifact_path=\"model\")\n",
    "\n",
    "        fig = plt.figure()\n",
    "        fig.add_subplot()\n",
    "        hplt.main_plot_histogram(trials, do_show=False)\n",
    "        mlflow.log_figure(fig, \"loss_histogram.png\")\n",
    "\n",
    "        return trials, best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfspace = {\n",
    "    \"n_estimators\": hp.uniform(\"n_estimators\", 200, 1000),\n",
    "    \"max_depth\": hp.quniform(\"max_depth\", 10, 1200, 10),\n",
    "    \"min_samples_split\": hp.uniform(\"min_samples_split\", 0.1, 1.0),\n",
    "    \"min_samples_leaf\": hp.uniform(\"min_samples_leaf\", 0.1, 0.5),\n",
    "    \"max_features\": hp.choice(\"max_features\", options=[None, 'sqrt', 'log2']),\n",
    "    \"criterion\": hp.choice(\"criterion\", ['squared_error', 'poisson', 'absolute_error', 'friedman_mse'])\n",
    "}\n",
    "\n",
    "\n",
    "gbmspace = {\n",
    "    'n_estimators': hp.quniform('n_estimators', 50, 200, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -5, 0),\n",
    "    'max_depth': hp.choice('max_depth', [None, hp.quniform('max_depth_val', 3, 10, 1)]),\n",
    "    'min_samples_split': hp.uniform('min_samples_split', 0.1, 1.0),\n",
    "    'min_samples_leaf': hp.uniform('min_samples_leaf', 0.1, 0.5),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'max_features': hp.choice('max_features', ['sqrt', 'log2', None]),\n",
    "}\n",
    "\n",
    "\n",
    "rfdtypes = {\"max_depth\": lambda x: int(x), \"n_estimators\": lambda x: int(x)}\n",
    "gbmdtypes = {\"max_depth\": lambda x: int(x) if x is not None else x, \"n_estimators\": lambda x: int(x)}\n",
    "\n",
    "data = data.astype(float)\n",
    "\n",
    "models = [RandomForestRegressor, GradientBoostingRegressor]\n",
    "for model, grid, dtype in zip(models, [rfspace, gbmspace], [rfdtypes, gbmdtypes]):\n",
    "    search(grid, data, 'Adj Close', model, dtype, max_evals=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No runs found\n"
     ]
    }
   ],
   "source": [
    "last_run = mlflow.last_active_run()\n",
    "try:\n",
    "    child_runs = mlflow.search_runs(\n",
    "        filter_string=f\"tags.mlflow.parentRunId='{last_run.info.run_id}'\"\n",
    "    )\n",
    "    with pd.option_context(\"display.max_columns\", None):\n",
    "        print(child_runs.sort_values(by='metrics.mae'))\n",
    "except AttributeError: print(\"No runs found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data store within workspace\n",
    "load_dotenv(find_dotenv())\n",
    "connection_string = os.environ.get('AZURE_STORAGE_CONNECTION_STRING')\n",
    "container = os.environ.get('CONTAINER_NAME')\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container)\n",
    "\n",
    "main_blob_name = 'ftse100data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data_to_blob(blob_name: str, df: pd.DataFrame, overwrite: bool = True) -> None:\n",
    "    container_client.upload_blob(name=blob_name, data=df.to_csv(), overwrite=overwrite)\n",
    "\n",
    "def read_data_from_blob(blob_name: str) -> pd.DataFrame:\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    data = blob_client.download_blob().readall().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(data), parse_dates=['Date'])\n",
    "    return df.set_index('Date')\n",
    "\n",
    "#data = read_data_from_blob(main_blob_name)\n",
    "#data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2: logging model in model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: .\\config.json\n"
     ]
    }
   ],
   "source": [
    "credential = DefaultAzureCredential() # this will prompt a sign-in if necessary\n",
    "mlclient = MLClient.from_config(credential) # reads config.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id                                      5727663c-084e-4c18-a007-b8d69d67691d\n",
      "experiment_id                               d2f4cd6e-b006-4000-9b48-2f1916d8f10a\n",
      "status                                                                  FINISHED\n",
      "artifact_uri                                                                    \n",
      "start_time                                      2024-01-15 17:26:09.370000+00:00\n",
      "end_time                                        2024-01-15 17:30:09.125000+00:00\n",
      "metrics.medae                                                             487.75\n",
      "metrics.msle                                                            0.010807\n",
      "metrics.r2                                                               0.69373\n",
      "metrics.mse                                                        321056.233024\n",
      "metrics.loss                                                                 NaN\n",
      "metrics.rmse                                                          566.618243\n",
      "metrics.mae                                                           486.152783\n",
      "metrics.best_mse                                                   321056.233024\n",
      "metrics.training_mean_absolute_error                                  476.334775\n",
      "metrics.training_r2_score                                               0.688775\n",
      "metrics.training_root_mean_squared_error                              558.755471\n",
      "metrics.training_mean_squared_error                                312207.676308\n",
      "metrics.training_score                                                  0.688775\n",
      "params.opt_learning_rate                                                    None\n",
      "params.opt_global_clipnorm                                                  None\n",
      "params.opt_ema_overwrite_frequency                                          None\n",
      "params.opt_weight_decay                                                     None\n",
      "params.opt_name                                                             None\n",
      "params.shuffle                                                              None\n",
      "params.validation_steps                                                     None\n",
      "params.class_weight                                                         None\n",
      "params.use_multiprocessing                                                  None\n",
      "params.steps_per_epoch                                                      None\n",
      "params.epochs                                                               None\n",
      "params.validation_freq                                                      None\n",
      "params.opt_use_ema                                                          None\n",
      "params.workers                                                              None\n",
      "params.validation_batch_size                                                None\n",
      "params.initial_epoch                                                        None\n",
      "params.opt_beta_2                                                           None\n",
      "params.max_queue_size                                                       None\n",
      "params.sample_weight                                                        None\n",
      "params.batch_size                                                           None\n",
      "params.opt_amsgrad                                                          None\n",
      "params.opt_clipvalue                                                        None\n",
      "params.validation_split                                                     None\n",
      "params.opt_beta_1                                                           None\n",
      "params.opt_ema_momentum                                                     None\n",
      "params.opt_epsilon                                                          None\n",
      "params.opt_is_legacy_optimizer                                              None\n",
      "params.opt_clipnorm                                                         None\n",
      "params.opt_jit_compile                                                      None\n",
      "params.best_n_estimators                                       599.6974200744851\n",
      "params.best_min_samples_split                                0.16146668771962497\n",
      "params.best_criterion                                                          0\n",
      "params.best_max_features                                                       0\n",
      "params.best_run_id                          6651ba31-eeac-4b4d-a021-39659af5ba27\n",
      "params.best_max_depth                                                      890.0\n",
      "params.best_min_samples_leaf                                  0.2630547735488422\n",
      "params.criterion                                                            None\n",
      "params.max_features                                                         None\n",
      "params.max_leaf_nodes                                                       None\n",
      "params.max_depth                                                            None\n",
      "params.min_samples_split                                                    None\n",
      "params.n_jobs                                                               None\n",
      "params.bootstrap                                                            None\n",
      "params.min_samples_leaf                                                     None\n",
      "params.oob_score                                                            None\n",
      "params.ccp_alpha                                                            None\n",
      "params.min_weight_fraction_leaf                                             None\n",
      "params.random_state                                                         None\n",
      "params.warm_start                                                           None\n",
      "params.min_impurity_decrease                                                None\n",
      "params.max_samples                                                          None\n",
      "params.verbose                                                              None\n",
      "params.n_estimators                                                         None\n",
      "params.validation_fraction                                                  None\n",
      "params.tol                                                                  None\n",
      "params.n_iter_no_change                                                     None\n",
      "params.loss                                                                 None\n",
      "params.subsample                                                            None\n",
      "params.alpha                                                                None\n",
      "params.learning_rate                                                        None\n",
      "params.init                                                                 None\n",
      "tags.mlflow.user                                                  samuel.hnatiuk\n",
      "tags.mlflow.runName                                        RandomForestRegressor\n",
      "tags.mlflow.rootRunId                       5727663c-084e-4c18-a007-b8d69d67691d\n",
      "tags.mlflow.parentRunId                                                     None\n",
      "tags.estimator_name                                                         None\n",
      "tags.estimator_class                                                        None\n",
      "Name: 1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "exp = mlflow.get_experiment_by_name('demo4')\n",
    "last_run = mlflow.search_runs(exp.experiment_id)\n",
    "our_run = last_run.loc[last_run['tags.mlflow.runName'] == 'RandomForestRegressor'].squeeze()\n",
    "rid = our_run.run_id\n",
    "with pd.option_context(\"display.max_rows\", None): print(our_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'lstm' already exists. Creating a new version of this model...\n",
      "2024/01/16 14:46:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: lstm, version 2\n",
      "Created version '2' of model 'lstm'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1705416370772, current_stage='None', description='', last_updated_timestamp=1705416370772, name='lstm', run_id='5727663c-084e-4c18-a007-b8d69d67691d', run_link='', source='azureml://uksouth.api.azureml.ms/mlflow/v2.0/subscriptions/b501a57e-71d5-4887-b72c-a0c961a0f281/resourceGroups/uk-environment/providers/Microsoft.MachineLearningServices/workspaces/daadspocs/experiments/d2f4cd6e-b006-4000-9b48-2f1916d8f10a/runs/5727663c-084e-4c18-a007-b8d69d67691d/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact_path = \"model\"\n",
    "mlflow.register_model(f\"runs:/{rid}/{artifact_path}\", \"lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_boring_cassava_smcw7bv63h_output_mlflow_log_model_548350309\n",
      "azureml_boring_cassava_smcw7bv63h_output_mlflow_log_model_1700531275\n",
      "credit_defaults_model\n",
      "amlstudio-predict-auto-price\n",
      "azureml_AutoML_cb7a19de-94bb-40e3-a109-6e2330f4023e_0_output_mlflow_log_model_805459951\n",
      "AutoMLcb7a19de90\n",
      "amlstudio-predict-diabetes\n",
      "azureml_5a48cbc5-ac10-4512-bb9f-4d6ac06c4468_output_mlflow_log_model_503845975\n",
      "azureml_loving_machine_3r8228hz83_output_mlflow_log_model_503845975\n",
      "diabetes-mlflow\n",
      "azureml_9f297f68-d9fa-4714-a98b-6546413102d5_output_mlflow_log_model_1899327965\n",
      "azureml_9f297f68-d9fa-4714-a98b-6546413102d5_output_mlflow_log_model_1938168045\n",
      "azureml_6651ba31-eeac-4b4d-a021-39659af5ba27_output_mlflow_log_model_613564256\n",
      "azureml_e84dddfe-1b66-4fa8-a8a0-c1c720cceed4_output_mlflow_log_model_613564256\n",
      "azureml_e0299110-ad86-4156-9a20-575cf5c8730d_output_mlflow_log_model_613564256\n",
      "azureml_e01e8cb3-4cc6-4d0e-8afd-ecc644103688_output_mlflow_log_model_613564256\n",
      "azureml_d947dee0-32e9-4bbf-bffc-4030fca49be1_output_mlflow_log_model_613564256\n",
      "azureml_d3f20700-294b-44c0-9cbd-99542e3ad236_output_mlflow_log_model_613564256\n",
      "azureml_f3613cd6-24d7-44c8-a3cf-c07d885f6e71_output_mlflow_log_model_613564256\n",
      "azureml_8923e17e-8e4a-4a06-a5e9-d1144d0e7ce7_output_mlflow_log_model_613564256\n",
      "azureml_378fc54d-35d8-403c-9b66-5cd2a2dd54c2_output_mlflow_log_model_1899327965\n",
      "azureml_c93fc14b-8ad2-4785-ad2d-24e6e1a957a7_output_mlflow_log_model_1899327965\n",
      "azureml_5b2d4b91-67b7-455a-9664-9331acc808c5_output_mlflow_log_model_1899327965\n",
      "lstm\n"
     ]
    }
   ],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "for model in client.search_registered_models():\n",
    "    print(f\"{model.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a913788\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ftsedemo-Ew-uKU1O-py3.11\\Lib\\site-packages\\mlflow\\store\\artifact\\utils\\models.py:32: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  latest = client.get_latest_versions(name, None if stage is None else [stage])\n",
      "c:\\Users\\a913788\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ftsedemo-Ew-uKU1O-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:01<00:00,  4.76it/s]\n",
      "2024/01/16 15:46:30 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - cloudpickle (current: 3.0.0, required: cloudpickle==2.2.0)\n",
      " - psutil (current: 5.9.7, required: psutil==5.8.0)\n",
      " - scikit-learn (current: 1.3.2, required: scikit-learn==0.24.1)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n",
      "2024/01/16 15:46:30 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.7.13`, differs from the version of Python that is currently running, `Python 3.11.0`, and may be incompatible\n",
      "c:\\Users\\a913788\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ftsedemo-Ew-uKU1O-py3.11\\Lib\\site-packages\\sklearn\\base.py:348: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 0.24.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('__eq__',\n",
       "  <bound method PyFuncModel.__eq__ of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.sklearn\n",
       "    run_id: 36b85079-2e17-43da-b4b4-775944b9a2d3\n",
       "  >),\n",
       " ('__init__',\n",
       "  <bound method PyFuncModel.__init__ of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.sklearn\n",
       "    run_id: 36b85079-2e17-43da-b4b4-775944b9a2d3\n",
       "  >),\n",
       " ('__repr__',\n",
       "  <bound method PyFuncModel.__repr__ of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.sklearn\n",
       "    run_id: 36b85079-2e17-43da-b4b4-775944b9a2d3\n",
       "  >),\n",
       " ('_predict_fn',\n",
       "  <bound method _SklearnModelWrapper.predict of <mlflow.sklearn._SklearnModelWrapper object at 0x00000242DE17DFD0>>),\n",
       " ('predict',\n",
       "  <bound method PyFuncModel.predict of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.sklearn\n",
       "    run_id: 36b85079-2e17-43da-b4b4-775944b9a2d3\n",
       "  >),\n",
       " ('unwrap_python_model',\n",
       "  <bound method PyFuncModel.unwrap_python_model of mlflow.pyfunc.loaded_model:\n",
       "    artifact_path: model\n",
       "    flavor: mlflow.sklearn\n",
       "    run_id: 36b85079-2e17-43da-b4b4-775944b9a2d3\n",
       "  >)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_model = mlflow.pyfunc.load_model(f\"models:/diabetes-mlflow/None\")\n",
    "inspect.getmembers(diab_model, predicate=inspect.ismethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<RegisteredModel: aliases={}, creation_timestamp=1705340501921, description='', last_updated_timestamp=1705340501921, latest_versions=[<ModelVersion: aliases=[], creation_timestamp=1705341048135, current_stage='Staging', description='', last_updated_timestamp=1705398650887, name='lstm', run_id='5727663c-084e-4c18-a007-b8d69d67691d', run_link='', source='azureml://uksouth.api.azureml.ms/mlflow/v2.0/subscriptions/b501a57e-71d5-4887-b72c-a0c961a0f281/resourceGroups/uk-environment/providers/Microsoft.MachineLearningServices/workspaces/daadspocs/experiments/d2f4cd6e-b006-4000-9b48-2f1916d8f10a/runs/5727663c-084e-4c18-a007-b8d69d67691d/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>,\n",
       "  <ModelVersion: aliases=[], creation_timestamp=1705416370772, current_stage='None', description='', last_updated_timestamp=1705416370772, name='lstm', run_id='5727663c-084e-4c18-a007-b8d69d67691d', run_link='', source='azureml://uksouth.api.azureml.ms/mlflow/v2.0/subscriptions/b501a57e-71d5-4887-b72c-a0c961a0f281/resourceGroups/uk-environment/providers/Microsoft.MachineLearningServices/workspaces/daadspocs/experiments/d2f4cd6e-b006-4000-9b48-2f1916d8f10a/runs/5727663c-084e-4c18-a007-b8d69d67691d/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>], name='lstm', tags={}>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_registered_models(f\"name='lstm'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelVersion: aliases=[], creation_timestamp=1705416370772, current_stage='None', description='', last_updated_timestamp=1705416370772, name='lstm', run_id='5727663c-084e-4c18-a007-b8d69d67691d', run_link='', source='azureml://uksouth.api.azureml.ms/mlflow/v2.0/subscriptions/b501a57e-71d5-4887-b72c-a0c961a0f281/resourceGroups/uk-environment/providers/Microsoft.MachineLearningServices/workspaces/daadspocs/experiments/d2f4cd6e-b006-4000-9b48-2f1916d8f10a/runs/5727663c-084e-4c18-a007-b8d69d67691d/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>,\n",
       " <ModelVersion: aliases=[], creation_timestamp=1705341048135, current_stage='Staging', description='', last_updated_timestamp=1705398650887, name='lstm', run_id='5727663c-084e-4c18-a007-b8d69d67691d', run_link='', source='azureml://uksouth.api.azureml.ms/mlflow/v2.0/subscriptions/b501a57e-71d5-4887-b72c-a0c961a0f281/resourceGroups/uk-environment/providers/Microsoft.MachineLearningServices/workspaces/daadspocs/experiments/d2f4cd6e-b006-4000-9b48-2f1916d8f10a/runs/5727663c-084e-4c18-a007-b8d69d67691d/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='1'>]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_model_versions(f\"name='lstm'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "client = MlflowClient()\n",
    "client.copy_model_version(\n",
    "    src_model_uri=\"models:/regression-model-staging@candidate\",\n",
    "    dst_name=\"regression-model-production\",\n",
    ")\n",
    "\"\"\" # look into this tomorrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a913788\\AppData\\Local\\Temp\\ipykernel_15796\\673679136.py:1: FutureWarning:\n",
      "\n",
      "``mlflow.tracking.client.MlflowClient.get_model_version_stages`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['None', 'Staging', 'Production', 'Archived']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_model_version_stages('lstm', version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a913788\\AppData\\Local\\Temp\\ipykernel_15796\\4093261154.py:1: FutureWarning:\n",
      "\n",
      "``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1705416370772, current_stage='Production', description='', last_updated_timestamp=1705417109695, name='lstm', run_id='5727663c-084e-4c18-a007-b8d69d67691d', run_link='', source='azureml://uksouth.api.azureml.ms/mlflow/v2.0/subscriptions/b501a57e-71d5-4887-b72c-a0c961a0f281/resourceGroups/uk-environment/providers/Microsoft.MachineLearningServices/workspaces/daadspocs/experiments/d2f4cd6e-b006-4000-9b48-2f1916d8f10a/runs/5727663c-084e-4c18-a007-b8d69d67691d/artifacts/model', status='READY', status_message='', tags={}, user_id='', version='2'>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.transition_model_version_stage('lstm', version=2, stage='Production', archive_existing_versions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mget_model_version_stages(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlstm\u001b[39m\u001b[38;5;124m\"\u001b[39m, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "client.get_model_version_stages(\"lstm\", version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3: model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ftse100demo-12132267894507554523'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_arr = np.random.randint(low=0, high=10, size=20)\n",
    "suffix = \"\".join(random_arr.astype(str))\n",
    "endpoint_name = f\"ftse100demo-{suffix}\"\n",
    "endpoint_name\n",
    "\n",
    "# add model deployment to endpoint here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hopefully everything from here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_client = get_deploy_client(mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_name = os.environ.get('ENDPOINT_NAME')\n",
    "deployment_name = 'ftse100demo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = deployment_client.create_endpoint(ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_client.delete_endpoint(ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctypes\n",
    "ctypes.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ftse100demo-12132267894507554523.uksouth.inference.ml.azure.com/score\n"
     ]
    }
   ],
   "source": [
    "scoring_uri = deployment_client.get_endpoint(endpoint=ep_name)[\"properties\"][\n",
    "    \"scoringUri\"\n",
    "]\n",
    "print(scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_config = {\n",
    "    \"instance_type\": \"Standard_DS2_v2\",\n",
    "    \"instance_count\": 1,\n",
    "}\n",
    "with open(\"deployment_config.json\", \"w\") as j:\n",
    "    j.write(json.dumps(deploy_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_config = {\n",
    "    \"traffic\": {deployment_name: 100}\n",
    "}\n",
    "\n",
    "with open(\"traffic_config.json\", \"w\") as j:\n",
    "    j.write(json.dumps(traffic_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a913788\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ftsedemo-Ew-uKU1O-py3.11\\Lib\\site-packages\\azureml\\mlflow\\deploy\\_util.py:64: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_model_version_stages`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  if model_stage_or_version in client.get_model_version_stages(None, None):\n",
      "c:\\Users\\a913788\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ftsedemo-Ew-uKU1O-py3.11\\Lib\\site-packages\\azureml\\mlflow\\deploy\\_util.py:66: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  model_version = client.get_latest_versions(model_name, [model_stage_or_version])[0].version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................................................................."
     ]
    }
   ],
   "source": [
    "dep = deployment_client.create_deployment(\n",
    "    name=deployment_name,\n",
    "    endpoint=ep_name,\n",
    "    model_uri=\"models:/lstm/Staging\",\n",
    "    config={\n",
    "        \"deploy-config-file\": \"deployment_config.json\",\n",
    "        \"endpoint-config-file\": \"traffic_config.json\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...to here is not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>7168.700195</td>\n",
       "      <td>7168.700195</td>\n",
       "      <td>7083.200195</td>\n",
       "      <td>7129.200195</td>\n",
       "      <td>724509800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>7129.200195</td>\n",
       "      <td>7196.100098</td>\n",
       "      <td>7105.299805</td>\n",
       "      <td>7122.299805</td>\n",
       "      <td>867111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>7122.299805</td>\n",
       "      <td>7246.299805</td>\n",
       "      <td>7122.299805</td>\n",
       "      <td>7232.299805</td>\n",
       "      <td>637274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>7232.299805</td>\n",
       "      <td>7344.700195</td>\n",
       "      <td>7232.299805</td>\n",
       "      <td>7339.899902</td>\n",
       "      <td>783615400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>7339.899902</td>\n",
       "      <td>7378.899902</td>\n",
       "      <td>7333.600098</td>\n",
       "      <td>7337.399902</td>\n",
       "      <td>776663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>7694.200195</td>\n",
       "      <td>7717.500000</td>\n",
       "      <td>7675.100098</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>703141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7647.399902</td>\n",
       "      <td>7651.799805</td>\n",
       "      <td>668838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>7651.799805</td>\n",
       "      <td>7693.899902</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>1306895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7655.200195</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7624.899902</td>\n",
       "      <td>794125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>7624.899902</td>\n",
       "      <td>7637.799805</td>\n",
       "      <td>7578.299805</td>\n",
       "      <td>7594.899902</td>\n",
       "      <td>740769500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>531 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low    Adj Close      Volume\n",
       "Date                                                                      \n",
       "2021-12-02  7168.700195  7168.700195  7083.200195  7129.200195   724509800\n",
       "2021-12-03  7129.200195  7196.100098  7105.299805  7122.299805   867111100\n",
       "2021-12-06  7122.299805  7246.299805  7122.299805  7232.299805   637274000\n",
       "2021-12-07  7232.299805  7344.700195  7232.299805  7339.899902   783615400\n",
       "2021-12-08  7339.899902  7378.899902  7333.600098  7337.399902   776663000\n",
       "...                 ...          ...          ...          ...         ...\n",
       "2024-01-09  7694.200195  7717.500000  7675.100098  7684.000000   703141300\n",
       "2024-01-10  7684.000000  7684.000000  7647.399902  7651.799805   668838800\n",
       "2024-01-11  7651.799805  7693.899902  7576.600098  7576.600098  1306895000\n",
       "2024-01-12  7576.600098  7655.200195  7576.600098  7624.899902   794125500\n",
       "2024-01-15  7624.899902  7637.799805  7578.299805  7594.899902   740769500\n",
       "\n",
       "[531 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = yf.download(\"^FTSE\", start=\"2021-12-02\")\n",
    "newdata = newdata.drop(newdata.tail(1).index) # as no volume for current day\n",
    "newdata = newdata.drop('Close', axis=1)\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = newdata.head(30).drop('Adj Close', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a913788\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ftsedemo-Ew-uKU1O-py3.11\\Lib\\site-packages\\mlflow\\store\\artifact\\utils\\models.py:32: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.9.2/model-registry.html#migrating-from-stages\n",
      "  latest = client.get_latest_versions(name, None if stage is None else [stage])\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00,  7.12it/s]\n"
     ]
    }
   ],
   "source": [
    "model = mlflow.pyfunc.load_model(f\"models:/lstm/Staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-12-02</th>\n",
       "      <td>7168.700195</td>\n",
       "      <td>7168.700195</td>\n",
       "      <td>7083.200195</td>\n",
       "      <td>7129.200195</td>\n",
       "      <td>7129.200195</td>\n",
       "      <td>724509800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-03</th>\n",
       "      <td>7129.200195</td>\n",
       "      <td>7196.100098</td>\n",
       "      <td>7105.299805</td>\n",
       "      <td>7122.299805</td>\n",
       "      <td>7122.299805</td>\n",
       "      <td>867111100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-06</th>\n",
       "      <td>7122.299805</td>\n",
       "      <td>7246.299805</td>\n",
       "      <td>7122.299805</td>\n",
       "      <td>7232.299805</td>\n",
       "      <td>7232.299805</td>\n",
       "      <td>637274000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-07</th>\n",
       "      <td>7232.299805</td>\n",
       "      <td>7344.700195</td>\n",
       "      <td>7232.299805</td>\n",
       "      <td>7339.899902</td>\n",
       "      <td>7339.899902</td>\n",
       "      <td>783615400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-08</th>\n",
       "      <td>7339.899902</td>\n",
       "      <td>7378.899902</td>\n",
       "      <td>7333.600098</td>\n",
       "      <td>7337.399902</td>\n",
       "      <td>7337.399902</td>\n",
       "      <td>776663000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>7694.200195</td>\n",
       "      <td>7717.500000</td>\n",
       "      <td>7675.100098</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>703141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7647.399902</td>\n",
       "      <td>7651.799805</td>\n",
       "      <td>7651.799805</td>\n",
       "      <td>668838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>7651.799805</td>\n",
       "      <td>7693.899902</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>1306895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7655.200195</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7624.899902</td>\n",
       "      <td>7624.899902</td>\n",
       "      <td>794125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>7624.899902</td>\n",
       "      <td>7637.799805</td>\n",
       "      <td>7578.299805</td>\n",
       "      <td>7594.899902</td>\n",
       "      <td>7594.899902</td>\n",
       "      <td>740769500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>531 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2021-12-02  7168.700195  7168.700195  7083.200195  7129.200195  7129.200195   \n",
       "2021-12-03  7129.200195  7196.100098  7105.299805  7122.299805  7122.299805   \n",
       "2021-12-06  7122.299805  7246.299805  7122.299805  7232.299805  7232.299805   \n",
       "2021-12-07  7232.299805  7344.700195  7232.299805  7339.899902  7339.899902   \n",
       "2021-12-08  7339.899902  7378.899902  7333.600098  7337.399902  7337.399902   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-01-09  7694.200195  7717.500000  7675.100098  7684.000000  7684.000000   \n",
       "2024-01-10  7684.000000  7684.000000  7647.399902  7651.799805  7651.799805   \n",
       "2024-01-11  7651.799805  7693.899902  7576.600098  7576.600098  7576.600098   \n",
       "2024-01-12  7576.600098  7655.200195  7576.600098  7624.899902  7624.899902   \n",
       "2024-01-15  7624.899902  7637.799805  7578.299805  7594.899902  7594.899902   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2021-12-02   724509800  \n",
       "2021-12-03   867111100  \n",
       "2021-12-06   637274000  \n",
       "2021-12-07   783615400  \n",
       "2021-12-08   776663000  \n",
       "...                ...  \n",
       "2024-01-09   703141300  \n",
       "2024-01-10   668838800  \n",
       "2024-01-11  1306895000  \n",
       "2024-01-12   794125500  \n",
       "2024-01-15   740769500  \n",
       "\n",
       "[531 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-12-01</th>\n",
       "      <td>6597.200195</td>\n",
       "      <td>6655.799805</td>\n",
       "      <td>6575.299805</td>\n",
       "      <td>6646.000000</td>\n",
       "      <td>6646.000000</td>\n",
       "      <td>642023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-02</th>\n",
       "      <td>6646.000000</td>\n",
       "      <td>6694.200195</td>\n",
       "      <td>6623.000000</td>\n",
       "      <td>6653.700195</td>\n",
       "      <td>6653.700195</td>\n",
       "      <td>946100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-03</th>\n",
       "      <td>6653.700195</td>\n",
       "      <td>6772.100098</td>\n",
       "      <td>6652.299805</td>\n",
       "      <td>6742.200195</td>\n",
       "      <td>6742.200195</td>\n",
       "      <td>954355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-06</th>\n",
       "      <td>6742.200195</td>\n",
       "      <td>6769.399902</td>\n",
       "      <td>6657.100098</td>\n",
       "      <td>6694.000000</td>\n",
       "      <td>6694.000000</td>\n",
       "      <td>640360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-12-07</th>\n",
       "      <td>6694.000000</td>\n",
       "      <td>6728.899902</td>\n",
       "      <td>6659.700195</td>\n",
       "      <td>6660.899902</td>\n",
       "      <td>6660.899902</td>\n",
       "      <td>729797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>7694.200195</td>\n",
       "      <td>7717.500000</td>\n",
       "      <td>7675.100098</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>703141300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7684.000000</td>\n",
       "      <td>7647.399902</td>\n",
       "      <td>7651.799805</td>\n",
       "      <td>7651.799805</td>\n",
       "      <td>668838800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-11</th>\n",
       "      <td>7651.799805</td>\n",
       "      <td>7693.899902</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>1306895000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-12</th>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7655.200195</td>\n",
       "      <td>7576.600098</td>\n",
       "      <td>7624.899902</td>\n",
       "      <td>7624.899902</td>\n",
       "      <td>794125500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-15</th>\n",
       "      <td>7624.899902</td>\n",
       "      <td>7637.799805</td>\n",
       "      <td>7578.299805</td>\n",
       "      <td>7594.899902</td>\n",
       "      <td>7594.899902</td>\n",
       "      <td>740769500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6089 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "1999-12-01  6597.200195  6655.799805  6575.299805  6646.000000  6646.000000   \n",
       "1999-12-02  6646.000000  6694.200195  6623.000000  6653.700195  6653.700195   \n",
       "1999-12-03  6653.700195  6772.100098  6652.299805  6742.200195  6742.200195   \n",
       "1999-12-06  6742.200195  6769.399902  6657.100098  6694.000000  6694.000000   \n",
       "1999-12-07  6694.000000  6728.899902  6659.700195  6660.899902  6660.899902   \n",
       "...                 ...          ...          ...          ...          ...   \n",
       "2024-01-09  7694.200195  7717.500000  7675.100098  7684.000000  7684.000000   \n",
       "2024-01-10  7684.000000  7684.000000  7647.399902  7651.799805  7651.799805   \n",
       "2024-01-11  7651.799805  7693.899902  7576.600098  7576.600098  7576.600098   \n",
       "2024-01-12  7576.600098  7655.200195  7576.600098  7624.899902  7624.899902   \n",
       "2024-01-15  7624.899902  7637.799805  7578.299805  7594.899902  7594.899902   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "1999-12-01   642023000  \n",
       "1999-12-02   946100000  \n",
       "1999-12-03   954355000  \n",
       "1999-12-06   640360000  \n",
       "1999-12-07   729797000  \n",
       "...                ...  \n",
       "2024-01-09   703141300  \n",
       "2024-01-10   668838800  \n",
       "2024-01-11  1306895000  \n",
       "2024-01-12   794125500  \n",
       "2024-01-15   740769500  \n",
       "\n",
       "[6089 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_update = pd.concat([data, newdata])\n",
    "data_update\n",
    "# save_data_to_blob(main_blob_name, data_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_feature_drift(reference_data: pd.DataFrame,\n",
    "                       new_data: pd.DataFrame,\n",
    "                       col_mapping: ColumnMapping) -> Dict[str, float]:\n",
    "\n",
    "    report = Report(metrics=[DataDriftPreset()])\n",
    "    report.run(reference_data=reference_data, current_data=new_data, column_mapping=col_mapping)\n",
    "    report_dict = report.as_dict()\n",
    "\n",
    "    drifts = {}\n",
    "\n",
    "    num_features = col_mapping.numerical_features if col_mapping.numerical_features else []\n",
    "    cat_features = col_mapping.categorical_features if col_mapping.categorical_features else []\n",
    "\n",
    "    for feature in num_features + cat_features:\n",
    "        drifts[feature] = report_dict[\"metrics\"][1][\"result\"][\"drift_by_columns\"][feature][\"drift_score\"]\n",
    "\n",
    "    drifts['drift_share'] = report_dict[\"metrics\"][0][\"result\"][\"drift_share\"]\n",
    "    return drifts, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/01/16 14:18:31 INFO mlflow.tracking.fluent: Experiment with name 'yyyeetttty' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Open', 'High', 'Low', 'Volume']\n",
      "['Open', 'High', 'Low', 'Volume']\n",
      "['Open', 'High', 'Low', 'Volume']\n"
     ]
    }
   ],
   "source": [
    "def log_drifts(old_data: pd.DataFrame,\n",
    "               new_data: pd.DataFrame,\n",
    "               target: str,\n",
    "               numerical_features: List[str] = [],\n",
    "               categorical_features: List[str] = [],\n",
    "               n_batch: int = 2) -> None:\n",
    "    \n",
    "    if not numerical_features and not categorical_features:\n",
    "        raise AttributeError(\"Features must be specified\")\n",
    "    \n",
    "    colmap = ColumnMapping()\n",
    "    if numerical_features: colmap.numerical_features = numerical_features\n",
    "    if categorical_features: colmap.categorical_features = categorical_features\n",
    "    colmap.target = target\n",
    "    \n",
    "    start, end = new_data.index.min(), new_data.index.max()\n",
    "    batch_idx = pd.date_range(start=start, end=end, periods=n_batch+1)\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"data_drift_{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"):\n",
    "\n",
    "        mlflow.log_param(\"new_data_start\", start)\n",
    "        mlflow.log_param(\"new_data_end\", end)\n",
    "\n",
    "        for idx, (sdate, edate) in enumerate(zip(batch_idx, batch_idx[1:])):\n",
    "\n",
    "            batch = newdata[(sdate <= newdata.index) & (newdata.index < edate)]\n",
    "\n",
    "            with mlflow.start_run(nested=True, run_name=f\"Batch {idx+1}\"):\n",
    "                mlflow.log_param(\"batch_start\", sdate)\n",
    "                mlflow.log_param(\"batch_end\", edate - pd.Timedelta(days=1))\n",
    "                batch_drifts, batch_report = eval_feature_drift(old_data, batch, colmap)\n",
    "                \n",
    "                batch_report.save_html(f'test{idx}.html')\n",
    "                mlflow.log_metrics(batch_drifts)\n",
    "                mlflow.log_artifact(f'test{idx}.html', artifact_path='reports')\n",
    "                os.remove(f\"test{idx}.html\")\n",
    "\n",
    "\n",
    "    \n",
    "        drifts, report = eval_feature_drift(old_data, new_data, colmap)\n",
    "\n",
    "        report.save_html('main.html')\n",
    "        mlflow.log_metrics(drifts)\n",
    "        mlflow.log_artifact('main.html', artifact_path='reports')\n",
    "        os.remove('main.html')\n",
    "\n",
    "    # next step: log plots to GO ALONG WUITH HIWESQPaw\n",
    "    return\n",
    "\n",
    "\n",
    "mlflow.set_experiment(experiment_name=\"yyyeetttty\")\n",
    "log_drifts(data, newdata, 'Adj Close', numerical_features=['Open', 'High', 'Low', 'Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigger_retrain(mean_error_threshold: float) -> None:\n",
    "\n",
    "    mlflow.start_run(run_name=\"lstm data drift check 3\")\n",
    "\n",
    "    avg_error = 0\n",
    "    list_of_errors = np.array([])\n",
    "    list_of_dates = np.array([])\n",
    "    threshold_broken = False\n",
    "\n",
    "    for date, column in newdata.iterrows():\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        with mlflow.start_run(nested=True, run_name=date.strftime(\"%Y-%m-%d\")):\n",
    "            day_data = column.to_frame().transpose()\n",
    "            X, y = day_data.drop('Adj Close', axis=1), day_data[['Adj Close']]\n",
    "            y_pred = model.predict(X)\n",
    "            error = (y-y_pred) ** 2\n",
    "\n",
    "            list_of_dates = np.append(list_of_dates, date)\n",
    "            list_of_errors = np.append(list_of_errors, error)\n",
    "\n",
    "            avg_error = np.average(list_of_errors)\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(list_of_dates, list_of_errors)\n",
    "            ax.set_title('MSE over time')\n",
    "            ax.set_xlabel('Date')\n",
    "            ax.set_ylabel('MSE')\n",
    "            ax.axhline(mean_error_threshold, color='r', linestyle='--')\n",
    "\n",
    "            plt.show()\n",
    "            mlflow.log_figure(fig, \"mse.png\")\n",
    "            \n",
    "            #df_to_log = pd.DataFrame(index=list_of_dates, data={'Error': list_of_errors})\n",
    "            #mlflow.log_artifact(df_to_log.to_csv('error.csv'), artifact_path=\"errors\")\n",
    "\n",
    "            mlflow.log_metric(\"rolling_mse\", avg_error)\n",
    "\n",
    "        if avg_error > mean_error_threshold:\n",
    "            threshold_broken = True\n",
    "            break\n",
    "\n",
    "    mlflow.end_run()\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if threshold_broken:\n",
    "        print(\"Drift threshold exceeded. Retraining...\")\n",
    "        \n",
    "        data_used = newdata[newdata.index <= (date)]\n",
    "        all_data = pd.concat([data, data_used])\n",
    "        runname = \"aalstm_retrain\"            \n",
    "        train_model(all_data, n_epochs=1, test_size=25)\n",
    "            \n",
    "\n",
    "trigger_retrain(1000000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftsedemo-Ew-uKU1O-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
